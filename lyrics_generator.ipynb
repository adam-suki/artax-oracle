{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ab980-c5d4-4630-85d8-6e2aa430a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc0e9a-39d3-4872-bd3d-204bb36ce6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/defthomes_musevana')\n",
    "data = open('data/corpus/defthomes_musevana_processed.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931cc46-8b62-4f49-bc6a-2e790ae881aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)\n",
    "\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\tfor i in range(1, len(token_list)):\n",
    "\t\tn_gram_sequence = token_list[:i+1]\n",
    "\t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10b01a-0d76-44f4-a25e-66b349b7d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_texts = [\n",
    "\"I watched you change Into a fly\",\n",
    "\"I looked away You were on fire\",\n",
    "\"I watched a change in you It's like you never had wings\",\n",
    "\"Now, you feel so alive I've watched you change\",\n",
    "\"I'm a rabbit in your headlights Scared of the spotlight\",\n",
    "\"You don't come to visit I'm stuck in this bed\",\n",
    "\"Thin rubber gloves She laughs when she's cryin'\",\n",
    "\"She cries when she's laughin'\",\n",
    "\"My knife it's sharp and chrome Come see inside my bones\",\n",
    "\"All of the fiends are on the block I'm the new king\",\n",
    "\"I take the queen\",\n",
    "\"When you were here before Couldn't look you in the eye\",\n",
    "\"You're just like an angel Your skin makes me cry\",\n",
    "\"You float like a feather In a beautiful world\",\n",
    "\"I wish I was special You're so fucking special\",\n",
    "\"But I'm a creep I'm a weirdo\",\n",
    "\"What the hell am I doing here? I don't belong here\",\n",
    "\"Standing in the middle of a hurricane\",\n",
    "\"rooted in the ground things tearing apart so organized\",\n",
    "\"These shadows don't need the light Spinning fast, screaming loud\",\n",
    "\"touching you gently harmony of destruction\",\n",
    "\"so quiet This noise donâ€™t need air\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8804e98-70a6-4793-acae-b8ba7abfa61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "next_words = 100\n",
    "\n",
    "for i, seed_text in enumerate(seed_texts):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    print(seed_text)\n",
    "    outfile = 'data/generated/ ' + str(i) + str(next_words) + '.txt'\n",
    "    with open(outfile, \"w\") as text_file:\n",
    "        text_file.write(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7d64a-f06c-4c7f-9e74-ee58b4a35233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rmoving seed texts\n",
    "texts = glob.glob('data/generated/*.txt')\n",
    "\n",
    "for text in texts:\n",
    "    f = open(text,'r')\n",
    "    lst = []\n",
    "    for line in f:\n",
    "        for word in seed_texts:\n",
    "            if word in line:\n",
    "                line = line.replace(word,'')\n",
    "        lst.append(line)\n",
    "    f.close()\n",
    "    f = open(text,'w')\n",
    "    for line in lst:\n",
    "        f.write(line)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480384a-c964-435d-b767-aa95281e4125",
   "metadata": {},
   "source": [
    "# Generating MIDIs\n",
    "Get vowels and assing notes to each one.import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff82462-c8af-4977-af5d-d3385fb4a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from utils.generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44ea11e-b860-4905-b840-df00d9d2d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "vh = {\n",
    "    'O' : 45,\n",
    "    'B' : 60,\n",
    "    'C' : 61,\n",
    "    'D' : 62,\n",
    "    'E' : 63,\n",
    "    'F' : 64,\n",
    "    'G' : 65,\n",
    "    'A' : 66,\n",
    "    'H' : 67,\n",
    "    'I' : 68,\n",
    "    'J' : 69,\n",
    "    'K' : 70,\n",
    "    'L' : 71,\n",
    "    'M' : 72,\n",
    "    'N' : 73,\n",
    "    'P' : 74,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6084bf9b-3e61-4e51-a8ad-013b9b0cac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_midi_from_vowels('data/generated/control-phoetics.txt', '1', vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae17997-c2f4-4354-b392-670b8d778c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = glob.glob('data/generated/*.txt', encoder=vh)\n",
    "for text in texts:\n",
    "    get_midi_from_vowels(text, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f106734-a59f-4efa-9654-22a33f43cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "texts = glob.glob('data/generated/*.txt')\n",
    "\n",
    "letters = ['a', 'e', 'i', 'o', 'u']\n",
    "notes = list(permutations([57, 60, 62, 64, 67]))\n",
    "\n",
    "for i in range(len(notes)):\n",
    "    encoder_permutation = {letters[x]: notes[i][x] for x in range(len(letters))}\n",
    "    encoder_permutation['O'] = 45\n",
    "    for text in texts:\n",
    "        get_midi_from_vowels(text, postfix=str(i), encoder=encoder_permutation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb23a23-02f5-4ded-a454-0fae7653b1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oracle] *",
   "language": "python",
   "name": "conda-env-oracle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
